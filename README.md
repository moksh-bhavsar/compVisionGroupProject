# YOLO + CLIP Image Classification Project

## Overview
This project combines the object detection capabilities of YOLO (You Only Look Once) with the advanced semantic analysis provided by CLIP (Contrastive Language-Image Pre-training) to enhance object detection and classification in images. This integration aims to leverage YOLO's robust detection capabilities to identify objects, which are then classified using CLIP based on their similarity to a set of predefined text descriptions.


## Setup

To run this project, you need to install the required Python libraries. You can install these libraries using the provided `requirements.txt` file:
Also, make sure that the absolute path to read-sign-detection folder is changed in road_sign.yaml file `finalProject\compVisionGroupProject\road_sign.yaml`:
# `path: C:\.....................\road-sign-detection`

```bash
pip install -r requirements.txt




