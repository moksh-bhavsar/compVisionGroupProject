{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet ultralytics\n",
    "%pip install --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from transformers import CLIPModel, CLIPProcessor, CLIPImageProcessor\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_YOLO = YOLO(model=\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "\n",
    "# # Function to get the data from XML Annotation\n",
    "# def extract_info_from_xml(xml_file):\n",
    "#     root = ET.parse(xml_file).getroot()\n",
    "    \n",
    "#     # Initialise the info dict \n",
    "#     info_dict = {}\n",
    "#     info_dict['bboxes'] = []\n",
    "\n",
    "#     # Parse the XML Tree\n",
    "#     for elem in root:\n",
    "#         # Get the file name \n",
    "#         if elem.tag == \"filename\":\n",
    "#             info_dict['filename'] = elem.text\n",
    "\n",
    "#         # Get the image size\n",
    "#         elif elem.tag == \"size\":\n",
    "#             image_size = []\n",
    "#             for subelem in elem:\n",
    "#                 image_size.append(int(subelem.text))\n",
    "            \n",
    "#             info_dict['image_size'] = tuple(image_size)\n",
    "        \n",
    "#         # Get details of the bounding box \n",
    "#         elif elem.tag == \"object\":\n",
    "#             bbox = {}\n",
    "#             for subelem in elem:\n",
    "#                 if subelem.tag == \"name\":\n",
    "#                     bbox[\"class\"] = subelem.text\n",
    "                    \n",
    "#                 elif subelem.tag == \"bndbox\":\n",
    "#                     for subsubelem in subelem:\n",
    "#                         bbox[subsubelem.tag] = int(subsubelem.text)            \n",
    "#             info_dict['bboxes'].append(bbox)\n",
    "    \n",
    "#     return info_dict\n",
    "\n",
    "# # Dictionary that maps class names to IDs\n",
    "# class_name_to_id_mapping = {\"trafficlight\": 0,\n",
    "#                            \"stop\": 1,\n",
    "#                            \"speedlimit\": 2,\n",
    "#                            \"crosswalk\": 3}\n",
    "\n",
    "# # Convert the info dict to the required yolo format and write it to disk\n",
    "# def convert_to_yolov5(info_dict, rootpath='.', write_to_file=False):\n",
    "#     print_buffer = []\n",
    "    \n",
    "#     # For each bounding box\n",
    "#     for b in info_dict[\"bboxes\"]:\n",
    "#         try:\n",
    "#             class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "#         except KeyError:\n",
    "#             print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "        \n",
    "#         # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "#         b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
    "#         b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
    "#         b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
    "#         b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
    "        \n",
    "#         # Normalise the co-ordinates by the dimensions of the image\n",
    "#         image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
    "#         b_center_x /= image_w \n",
    "#         b_center_y /= image_h \n",
    "#         b_width    /= image_w \n",
    "#         b_height   /= image_h \n",
    "        \n",
    "#         #Write the bbox details to the file \n",
    "#         print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "\n",
    "#     if write_to_file:\n",
    "#         # Name of the file which we have to save \n",
    "#         save_file_name = os.path.join(rootpath, \"annotations\", info_dict[\"filename\"].replace(\"png\", \"txt\"))\n",
    "    \n",
    "#         # Save the annotation to disk\n",
    "#         print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n",
    "#     else:\n",
    "#         return print_buffer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# %pip install tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Rootpath indicates the root folder where you have stored the road-sign-detection dataset\n",
    "# rootpath = \"/Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection\"\n",
    "\n",
    "# annotations = [os.path.join(rootpath,'annotations', x) for x in os.listdir(os.path.join(rootpath,'annotations')) if x[-3:] == \"xml\"]\n",
    "# annotations.sort()\n",
    "\n",
    "# for ann in tqdm(annotations):\n",
    "#     info_dict = extract_info_from_xml(ann)\n",
    "#     convert_to_yolov5(info_dict, rootpath=rootpath, write_to_file=True)\n",
    "# annotations = [os.path.join(rootpath,'annotations', x) for x in os.listdir(os.path.join(rootpath,'annotations')) if x[-3:] == \"txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# !pip install --quiet scikit-learn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# images = [os.path.join(rootpath, 'images', x) for x in os.listdir(os.path.join(rootpath, 'images'))]\n",
    "# annotations = [os.path.join(rootpath,'annotations', x) for x in os.listdir(os.path.join(rootpath,'annotations')) if x[-3:] == \"txt\"]\n",
    "\n",
    "# images.sort()\n",
    "# annotations.sort()\n",
    "\n",
    "# train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "# val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "\n",
    "# def move_files_to_folder(list_of_files, destination_folder):\n",
    "#     for f in list_of_files:\n",
    "#         try:\n",
    "#             shutil.move(f, destination_folder)\n",
    "#         except:\n",
    "#             print(f)\n",
    "#             assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_files_to_folder(train_images, 'road-sign-detection/images/train')\n",
    "# move_files_to_folder(val_images, 'road-sign-detection/images/val')\n",
    "# move_files_to_folder(test_images, 'road-sign-detection/images/test')\n",
    "# move_files_to_folder(train_annotations, 'road-sign-detection/labels/train/')\n",
    "# move_files_to_folder(val_annotations, 'road-sign-detection/labels/val/')\n",
    "# move_files_to_folder(test_annotations, 'road-sign-detection/labels/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_YOLO.train(data=\"./road_sign.yaml\", epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_to_id_mapping = {\"trafficlight\": 0,\n",
    "                           \"stop\": 1,\n",
    "                           \"speedlimit\": 2,\n",
    "                           \"crosswalk\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(val):\n",
    "   \n",
    "    for key, value in class_name_to_id_mapping.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.20 ðŸš€ Python-3.11.6 torch-2.1.1 CPU (Intel Core(TM) i7-1060NG7 1.20GHz)\n",
      "YOLOv5n summary (fused): 193 layers, 2503724 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/labels/val.cache... 88 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:18<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         88        126      0.954      0.611      0.799      0.676\n",
      "          trafficlight         88         20          1        0.2        0.6      0.438\n",
      "                  stop         88          7      0.833      0.714      0.833      0.673\n",
      "            speedlimit         88         76      0.984      0.789      0.892      0.811\n",
      "             crosswalk         88         23          1      0.739       0.87      0.781\n",
      "Speed: 4.5ms preprocess, 186.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model_YOLO.val(conf = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/precision(B)': 0.9542349726775956,\n",
       " 'metrics/recall(B)': 0.6107224583197124,\n",
       " 'metrics/mAP50(B)': 0.7988092896174863,\n",
       " 'metrics/mAP50-95(B)': 0.6758273875482012,\n",
       " 'fitness': 0.6881255777551296}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road100.png: 640x640 (no detections), 329.5ms\n",
      "image 2/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road113.png: 448x640 (no detections), 243.9ms\n",
      "image 3/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road129.png: 448x640 1 trafficlight, 1 crosswalk, 268.0ms\n",
      "image 4/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road140.png: 448x640 1 crosswalk, 249.5ms\n",
      "image 5/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road142.png: 640x448 1 crosswalk, 278.3ms\n",
      "image 6/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road143.png: 640x448 1 crosswalk, 220.4ms\n",
      "image 7/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road157.png: 640x480 1 speedlimit, 397.0ms\n",
      "image 8/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road160.png: 640x480 1 stop, 1 crosswalk, 221.7ms\n",
      "image 9/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road164.png: 640x480 (no detections), 215.7ms\n",
      "image 10/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road174.png: 640x480 1 speedlimit, 233.7ms\n",
      "image 11/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road175.png: 640x480 1 speedlimit, 181.4ms\n",
      "image 12/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road18.png: 640x512 (no detections), 337.4ms\n",
      "image 13/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road183.png: 640x480 1 crosswalk, 233.5ms\n",
      "image 14/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road194.png: 640x480 1 crosswalk, 233.4ms\n",
      "image 15/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road199.png: 640x480 1 speedlimit, 233.4ms\n",
      "image 16/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road206.png: 640x480 (no detections), 230.0ms\n",
      "image 17/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road261.png: 640x480 1 speedlimit, 215.9ms\n",
      "image 18/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road267.png: 640x480 1 speedlimit, 192.0ms\n",
      "image 19/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road293.png: 640x480 1 speedlimit, 204.0ms\n",
      "image 20/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road3.png: 480x640 1 trafficlight, 240.9ms\n",
      "image 21/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road315.png: 640x480 1 speedlimit, 227.8ms\n",
      "image 22/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road316.png: 640x480 1 speedlimit, 1 crosswalk, 236.9ms\n",
      "image 23/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road318.png: 640x480 1 speedlimit, 1 crosswalk, 179.7ms\n",
      "image 24/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road321.png: 640x480 1 speedlimit, 1 crosswalk, 210.7ms\n",
      "image 25/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road328.png: 640x480 1 speedlimit, 278.5ms\n",
      "image 26/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road33.png: 640x448 (no detections), 186.9ms\n",
      "image 27/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road337.png: 640x480 1 speedlimit, 189.5ms\n",
      "image 28/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road356.png: 640x480 (no detections), 198.0ms\n",
      "image 29/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road360.png: 640x480 1 speedlimit, 201.3ms\n",
      "image 30/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road367.png: 640x480 1 speedlimit, 191.0ms\n",
      "image 31/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road37.png: 640x448 1 trafficlight, 203.1ms\n",
      "image 32/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road385.png: 640x480 1 speedlimit, 225.5ms\n",
      "image 33/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road403.png: 640x480 1 speedlimit, 179.0ms\n",
      "image 34/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road408.png: 640x480 (no detections), 178.1ms\n",
      "image 35/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road417.png: 640x480 1 speedlimit, 173.7ms\n",
      "image 36/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road418.png: 640x480 1 speedlimit, 194.2ms\n",
      "image 37/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road43.png: 448x640 (no detections), 163.2ms\n",
      "image 38/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road431.png: 640x480 1 speedlimit, 182.4ms\n",
      "image 39/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road433.png: 640x480 1 speedlimit, 178.1ms\n",
      "image 40/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road445.png: 640x480 1 speedlimit, 171.5ms\n",
      "image 41/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road47.png: 448x640 (no detections), 243.3ms\n",
      "image 42/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road486.png: 640x480 1 speedlimit, 244.5ms\n",
      "image 43/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road490.png: 640x480 1 speedlimit, 188.1ms\n",
      "image 44/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road492.png: 640x480 1 speedlimit, 172.5ms\n",
      "image 45/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road494.png: 640x480 (no detections), 174.3ms\n",
      "image 46/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road498.png: 640x480 1 speedlimit, 168.8ms\n",
      "image 47/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road50.png: 640x448 (no detections), 165.8ms\n",
      "image 48/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road543.png: 640x480 1 speedlimit, 173.9ms\n",
      "image 49/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road547.png: 640x480 1 speedlimit, 2 crosswalks, 178.8ms\n",
      "image 50/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road550.png: 640x480 1 speedlimit, 184.9ms\n",
      "image 51/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road558.png: 640x480 1 speedlimit, 166.4ms\n",
      "image 52/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road563.png: 640x480 1 speedlimit, 1 crosswalk, 175.7ms\n",
      "image 53/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road564.png: 640x480 1 speedlimit, 1 crosswalk, 217.7ms\n",
      "image 54/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road590.png: 640x480 1 speedlimit, 206.2ms\n",
      "image 55/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road599.png: 640x480 1 speedlimit, 161.3ms\n",
      "image 56/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road600.png: 640x480 1 speedlimit, 176.3ms\n",
      "image 57/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road609.png: 640x480 1 speedlimit, 1 crosswalk, 177.6ms\n",
      "image 58/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road617.png: 640x480 1 speedlimit, 175.1ms\n",
      "image 59/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road625.png: 640x480 1 speedlimit, 168.9ms\n",
      "image 60/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road640.png: 640x480 1 speedlimit, 164.4ms\n",
      "image 61/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road643.png: 640x480 (no detections), 169.7ms\n",
      "image 62/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road661.png: 640x480 1 speedlimit, 189.0ms\n",
      "image 63/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road665.png: 640x480 1 speedlimit, 223.6ms\n",
      "image 64/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road667.png: 640x480 1 speedlimit, 220.8ms\n",
      "image 65/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road67.png: 448x640 1 stop, 194.2ms\n",
      "image 66/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road672.png: 640x480 (no detections), 178.1ms\n",
      "image 67/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road679.png: 640x480 1 speedlimit, 162.2ms\n",
      "image 68/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road695.png: 640x480 (no detections), 167.7ms\n",
      "image 69/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road709.png: 640x480 (no detections), 277.8ms\n",
      "image 70/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road712.png: 640x480 (no detections), 192.4ms\n",
      "image 71/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road721.png: 640x480 1 speedlimit, 182.9ms\n",
      "image 72/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road730.png: 640x480 2 speedlimits, 197.4ms\n",
      "image 73/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road731.png: 640x480 2 speedlimits, 169.7ms\n",
      "image 74/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road748.png: 640x480 (no detections), 183.6ms\n",
      "image 75/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road764.png: 640x480 1 speedlimit, 214.3ms\n",
      "image 76/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road784.png: 640x480 1 speedlimit, 1 crosswalk, 184.4ms\n",
      "image 77/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road789.png: 640x480 1 speedlimit, 193.2ms\n",
      "image 78/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road796.png: 640x480 (no detections), 173.6ms\n",
      "image 79/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road80.png: 640x640 2 stops, 231.7ms\n",
      "image 80/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road801.png: 640x480 1 speedlimit, 169.5ms\n",
      "image 81/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road803.png: 640x480 1 speedlimit, 171.3ms\n",
      "image 82/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road804.png: 640x480 1 speedlimit, 188.9ms\n",
      "image 83/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road809.png: 640x480 1 speedlimit, 187.1ms\n",
      "image 84/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road819.png: 640x480 (no detections), 216.9ms\n",
      "image 85/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road841.png: 640x480 1 speedlimit, 1 crosswalk, 259.2ms\n",
      "image 86/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road854.png: 640x480 1 speedlimit, 195.4ms\n",
      "image 87/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road91.png: 640x640 1 stop, 222.4ms\n",
      "image 88/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road96.png: 448x640 1 stop, 154.2ms\n",
      "Speed: 5.4ms preprocess, 205.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_path = \"road-sign-detection/images/val/\"\n",
    "result = model_YOLO.predict(source=test_path, conf = 0.5, save_crop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road321.png: 640x480 1 speedlimit, 1 crosswalk, 242.6ms\n",
      "Speed: 2.9ms preprocess, 242.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Run YOLO for object detection\n",
    "with torch.no_grad():\n",
    "    predictions = model_YOLO.predict(\"road-sign-detection/images/val/road321.png\")\n",
    "    boxes = predictions[0].boxes.xyxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[134.21416, 171.58974, 176.27206, 212.39563],\n",
       "        [ 73.86993, 287.23798, 102.32633, 315.04105]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([2., 3.])\n",
       "conf: tensor([0.67903, 0.64175])\n",
       "data: tensor([[134.21416, 171.58974, 176.27206, 212.39563,   0.67903,   2.00000],\n",
       "        [ 73.86993, 287.23798, 102.32633, 315.04105,   0.64175,   3.00000]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (400, 300)\n",
       "shape: torch.Size([2, 6])\n",
       "xywh: tensor([[155.24310, 191.99268,  42.05791,  40.80589],\n",
       "        [ 88.09813, 301.13953,  28.45640,  27.80307]])\n",
       "xywhn: tensor([[0.51748, 0.47998, 0.14019, 0.10201],\n",
       "        [0.29366, 0.75285, 0.09485, 0.06951]])\n",
       "xyxy: tensor([[134.21416, 171.58974, 176.27206, 212.39563],\n",
       "        [ 73.86993, 287.23798, 102.32633, 315.04105]])\n",
       "xyxyn: tensor([[0.44738, 0.42897, 0.58757, 0.53099],\n",
       "        [0.24623, 0.71809, 0.34109, 0.78760]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(text=[\"traffic light\", \"stop\",\"speed limit\", \"crosswalk\"], images=Image.open(\"road-sign-detection/images/val/road321.png\"), return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,  3399,  1395, 49407],\n",
       "        [49406,  1691, 49407, 49407],\n",
       "        [49406,  4163,  9973, 49407],\n",
       "        [49406,  5266,  2374, 49407]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_per_image.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits_per_image', 'logits_per_text', 'text_embeds', 'image_embeds', 'text_model_output', 'vision_model_output'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_clip(file_dir:str):\n",
    "    yolo_model = YOLO(model=\"runs/detect/train/weights/best.pt\")\n",
    "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", pretrained=True)\n",
    "    results = yolo_model.predict(file_dir)\n",
    "    for result in results:\n",
    "        orig_image = result.orig_img\n",
    "        orig_image = cv.cvtColor(orig_image, cv.COLOR_BGR2RGB)\n",
    "        for i in range(len(result.boxes.cls)):\n",
    "            x1, x2, y1, y2 = map(int, result.boxes.xyxy[i])\n",
    "            print(f\"x1: {x1}, x2: {x2}, y1: {y1}, y2: {y2}\")\n",
    "            object_image = orig_image[y1:y2, x1:x2]\n",
    "            cls = get_key(result.boxes.cls[i])\n",
    "            text = \"a\" + cls\n",
    "            inputs = clip_processor(images=object_image, return_tensors=\"pt\", text=[text])\n",
    "            # tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "            # inputs = tokenizer([\"a stop sign\", \"a traffic light\"], padding=True, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                text_features = clip_model.get_text_features(**inputs)\n",
    "                image_features = clip_model.get_image_features(**inputs)\n",
    "            \n",
    "            similarity_score = 1 - torch.nn.functional.cosine_similarity(text_features, image_features, dim=-1)\n",
    "            print(f\"Similarity Score for {(result.path.split('/'))[-1]}:\", similarity_score.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road100.png: 640x640 (no detections), 174.5ms\n",
      "image 2/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road113.png: 448x640 (no detections), 126.4ms\n",
      "image 3/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road129.png: 448x640 1 trafficlight, 1 crosswalk, 122.2ms\n",
      "image 4/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road140.png: 448x640 1 crosswalk, 123.6ms\n",
      "image 5/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road142.png: 640x448 1 crosswalk, 120.9ms\n",
      "image 6/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road143.png: 640x448 1 crosswalk, 125.0ms\n",
      "image 7/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road157.png: 640x480 1 speedlimit, 150.3ms\n",
      "image 8/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road160.png: 640x480 1 stop, 1 crosswalk, 128.4ms\n",
      "image 9/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road164.png: 640x480 1 trafficlight, 126.3ms\n",
      "image 10/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road174.png: 640x480 1 speedlimit, 128.1ms\n",
      "image 11/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road175.png: 640x480 1 speedlimit, 129.5ms\n",
      "image 12/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road18.png: 640x512 (no detections), 140.7ms\n",
      "image 13/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road183.png: 640x480 1 crosswalk, 125.8ms\n",
      "image 14/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road194.png: 640x480 1 crosswalk, 127.6ms\n",
      "image 15/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road199.png: 640x480 1 speedlimit, 129.6ms\n",
      "image 16/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road206.png: 640x480 1 speedlimit, 136.0ms\n",
      "image 17/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road261.png: 640x480 1 speedlimit, 128.1ms\n",
      "image 18/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road267.png: 640x480 1 speedlimit, 133.0ms\n",
      "image 19/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road293.png: 640x480 1 speedlimit, 128.3ms\n",
      "image 20/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road3.png: 480x640 2 trafficlights, 130.9ms\n",
      "image 21/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road315.png: 640x480 1 speedlimit, 132.5ms\n",
      "image 22/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road316.png: 640x480 2 speedlimits, 1 crosswalk, 154.9ms\n",
      "image 23/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road318.png: 640x480 1 speedlimit, 1 crosswalk, 135.2ms\n",
      "image 24/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road321.png: 640x480 1 speedlimit, 1 crosswalk, 135.0ms\n",
      "image 25/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road328.png: 640x480 1 speedlimit, 136.1ms\n",
      "image 26/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road33.png: 640x448 (no detections), 207.8ms\n",
      "image 27/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road337.png: 640x480 1 speedlimit, 140.9ms\n",
      "image 28/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road356.png: 640x480 1 stop, 135.3ms\n",
      "image 29/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road360.png: 640x480 1 speedlimit, 170.7ms\n",
      "image 30/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road367.png: 640x480 1 speedlimit, 161.3ms\n",
      "image 31/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road37.png: 640x448 1 trafficlight, 127.3ms\n",
      "image 32/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road385.png: 640x480 1 speedlimit, 136.1ms\n",
      "image 33/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road403.png: 640x480 1 speedlimit, 133.6ms\n",
      "image 34/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road408.png: 640x480 1 speedlimit, 134.3ms\n",
      "image 35/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road417.png: 640x480 1 speedlimit, 144.8ms\n",
      "image 36/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road418.png: 640x480 1 speedlimit, 141.7ms\n",
      "image 37/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road43.png: 448x640 2 trafficlights, 122.3ms\n",
      "image 38/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road431.png: 640x480 1 speedlimit, 136.5ms\n",
      "image 39/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road433.png: 640x480 1 speedlimit, 134.3ms\n",
      "image 40/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road445.png: 640x480 1 speedlimit, 133.3ms\n",
      "image 41/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road47.png: 448x640 (no detections), 128.2ms\n",
      "image 42/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road486.png: 640x480 1 speedlimit, 135.3ms\n",
      "image 43/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road490.png: 640x480 1 speedlimit, 137.3ms\n",
      "image 44/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road492.png: 640x480 1 speedlimit, 136.0ms\n",
      "image 45/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road494.png: 640x480 1 crosswalk, 157.0ms\n",
      "image 46/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road498.png: 640x480 1 speedlimit, 137.4ms\n",
      "image 47/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road50.png: 640x448 1 trafficlight, 135.8ms\n",
      "image 48/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road543.png: 640x480 1 speedlimit, 130.6ms\n",
      "image 49/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road547.png: 640x480 1 speedlimit, 2 crosswalks, 136.6ms\n",
      "image 50/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road550.png: 640x480 1 speedlimit, 161.1ms\n",
      "image 51/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road558.png: 640x480 1 speedlimit, 132.9ms\n",
      "image 52/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road563.png: 640x480 1 speedlimit, 1 crosswalk, 128.3ms\n",
      "image 53/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road564.png: 640x480 1 speedlimit, 1 crosswalk, 133.1ms\n",
      "image 54/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road590.png: 640x480 1 speedlimit, 128.3ms\n",
      "image 55/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road599.png: 640x480 1 speedlimit, 129.6ms\n",
      "image 56/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road600.png: 640x480 1 speedlimit, 132.1ms\n",
      "image 57/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road609.png: 640x480 1 speedlimit, 1 crosswalk, 130.8ms\n",
      "image 58/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road617.png: 640x480 1 speedlimit, 130.9ms\n",
      "image 59/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road625.png: 640x480 1 speedlimit, 132.1ms\n",
      "image 60/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road640.png: 640x480 2 speedlimits, 134.2ms\n",
      "image 61/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road643.png: 640x480 1 speedlimit, 130.9ms\n",
      "image 62/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road661.png: 640x480 1 speedlimit, 131.6ms\n",
      "image 63/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road665.png: 640x480 2 speedlimits, 133.4ms\n",
      "image 64/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road667.png: 640x480 1 speedlimit, 140.0ms\n",
      "image 65/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road67.png: 448x640 1 stop, 142.6ms\n",
      "image 66/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road672.png: 640x480 1 speedlimit, 147.9ms\n",
      "image 67/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road679.png: 640x480 1 speedlimit, 166.8ms\n",
      "image 68/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road695.png: 640x480 2 speedlimits, 167.9ms\n",
      "image 69/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road709.png: 640x480 1 speedlimit, 158.9ms\n",
      "image 70/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road712.png: 640x480 2 speedlimits, 141.7ms\n",
      "image 71/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road721.png: 640x480 1 speedlimit, 140.7ms\n",
      "image 72/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road730.png: 640x480 2 speedlimits, 140.0ms\n",
      "image 73/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road731.png: 640x480 2 speedlimits, 136.9ms\n",
      "image 74/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road748.png: 640x480 2 speedlimits, 155.1ms\n",
      "image 75/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road764.png: 640x480 1 speedlimit, 169.1ms\n",
      "image 76/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road784.png: 640x480 1 speedlimit, 1 crosswalk, 148.3ms\n",
      "image 77/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road789.png: 640x480 1 speedlimit, 157.9ms\n",
      "image 78/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road796.png: 640x480 1 speedlimit, 194.0ms\n",
      "image 79/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road80.png: 640x640 3 stops, 190.5ms\n",
      "image 80/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road801.png: 640x480 1 speedlimit, 170.8ms\n",
      "image 81/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road803.png: 640x480 1 speedlimit, 155.5ms\n",
      "image 82/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road804.png: 640x480 1 speedlimit, 142.6ms\n",
      "image 83/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road809.png: 640x480 1 speedlimit, 138.4ms\n",
      "image 84/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road819.png: 640x480 1 trafficlight, 1 stop, 131.1ms\n",
      "image 85/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road841.png: 640x480 1 speedlimit, 1 crosswalk, 135.7ms\n",
      "image 86/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road854.png: 640x480 1 speedlimit, 142.4ms\n",
      "image 87/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road91.png: 640x640 1 stop, 197.9ms\n",
      "image 88/88 /Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road96.png: 448x640 1 stop, 149.6ms\n",
      "Speed: 3.4ms preprocess, 141.5ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "x1: 109, x2: 79, y1: 211, y2: 173\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43myolo_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroad-sign-detection/images/val/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[160], line 15\u001b[0m, in \u001b[0;36myolo_clip\u001b[0;34m(file_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m get_key(result\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mcls[i])\n\u001b[1;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m---> 15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mclip_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-base-patch32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#inputs = tokenizer([\"a stop sign\", \"a traffic light\"], padding=True, return_tensors=\"pt\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/models/clip/processing_clip.py:104\u001b[0m, in \u001b[0;36mCLIPProcessor.__call__\u001b[0;34m(self, text, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mpixel_values\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/models/clip/image_processing_clip.py:319\u001b[0m, in \u001b[0;36mCLIPImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, resample, do_center_crop, crop_size, do_rescale, rescale_factor, do_normalize, image_mean, image_std, do_convert_rgb, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m infer_channel_dimension_format(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[0;32m--> 319\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_center_crop:\n\u001b[1;32m    325\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_crop(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39mcrop_size, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    327\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/models/clip/image_processing_clip.py:320\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m infer_channel_dimension_format(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[1;32m    319\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 320\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    322\u001b[0m     ]\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_center_crop:\n\u001b[1;32m    325\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_crop(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39mcrop_size, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    327\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/models/clip/image_processing_clip.py:181\u001b[0m, in \u001b[0;36mCLIPImageProcessor.resize\u001b[0;34m(self, image, size, resample, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize must contain either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_edge\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[43mget_resize_output_image_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_to_square\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_to_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resize(\n\u001b[1;32m    188\u001b[0m     image,\n\u001b[1;32m    189\u001b[0m     size\u001b[38;5;241m=\u001b[39moutput_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/image_transforms.py:262\u001b[0m, in \u001b[0;36mget_resize_output_image_size\u001b[0;34m(input_image, size, default_to_square, max_size, input_data_format)\u001b[0m\n\u001b[1;32m    259\u001b[0m short, long \u001b[38;5;241m=\u001b[39m (width, height) \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m height \u001b[38;5;28;01melse\u001b[39;00m (height, width)\n\u001b[1;32m    260\u001b[0m requested_new_short \u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m--> 262\u001b[0m new_short, new_long \u001b[38;5;241m=\u001b[39m requested_new_short, \u001b[38;5;28mint\u001b[39m(\u001b[43mrequested_new_short\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlong\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshort\u001b[49m)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m requested_new_short:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "yolo_clip(\"road-sign-detection/images/val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_clip(\"road-sign-detection/images/val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ultralytics.models.yolo.model.YOLO,\n",
       " transformers.models.clip.modeling_clip.CLIPModel)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_YOLO), type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
       "obb: None\n",
       "orig_img: array([[[196, 199, 197],\n",
       "        [200, 200, 197],\n",
       "        [204, 204, 203],\n",
       "        ...,\n",
       "        [ 41,  32,  29],\n",
       "        [ 49,  41,  37],\n",
       "        [ 54,  45,  38]],\n",
       "\n",
       "       [[144, 145, 151],\n",
       "        [133, 132, 139],\n",
       "        [128, 128, 134],\n",
       "        ...,\n",
       "        [ 43,  35,  29],\n",
       "        [ 51,  42,  38],\n",
       "        [ 51,  43,  37]],\n",
       "\n",
       "       [[ 78,  78,  84],\n",
       "        [ 86,  87,  93],\n",
       "        [ 93,  94,  98],\n",
       "        ...,\n",
       "        [ 48,  39,  32],\n",
       "        [ 54,  45,  42],\n",
       "        [ 54,  44,  37]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[110, 100,  93],\n",
       "        [109,  99,  90],\n",
       "        [109,  99,  91],\n",
       "        ...,\n",
       "        [ 70,  65,  55],\n",
       "        [ 69,  63,  53],\n",
       "        [ 72,  63,  54]],\n",
       "\n",
       "       [[109, 100,  91],\n",
       "        [109,  99,  90],\n",
       "        [110, 100,  93],\n",
       "        ...,\n",
       "        [ 71,  66,  56],\n",
       "        [ 68,  61,  51],\n",
       "        [ 69,  59,  51]],\n",
       "\n",
       "       [[107,  99,  91],\n",
       "        [109, 100,  92],\n",
       "        [110, 101,  94],\n",
       "        ...,\n",
       "        [ 62,  61,  49],\n",
       "        [ 64,  61,  50],\n",
       "        [ 67,  63,  52]]], dtype=uint8)\n",
       "orig_shape: (400, 300)\n",
       "path: '/Users/moke/Comp Vision/groupProject/compVisionGroupProject/road-sign-detection/images/val/road321.png'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 2.9387474060058594, 'inference': 242.61975288391113, 'postprocess': 0.9589195251464844}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
